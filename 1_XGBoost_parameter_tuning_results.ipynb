{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5df12a-b4d4-43b9-ac3f-d3d9452630b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Lowest train_mse =====\n",
      "Iteration   : 249\n",
      "Timestamp   : 2025-08-08 17:45:44.365824\n",
      "train_mse   : 0.005010\n",
      "test_mse    : 0.018217\n",
      "train_r2    : 0.833303\n",
      "test_r2     : -0.376188\n",
      "params      :\n",
      "{'colsample_bytree': 0.360569,\n",
      " 'device': 'cuda',\n",
      " 'gamma': 0.003303,\n",
      " 'learning_rate': 0.184417,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8,\n",
      " 'n_estimators': 3250,\n",
      " 'n_jobs': -1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': 24.718484,\n",
      " 'reg_lambda': 4214.830235,\n",
      " 'subsample': 0.547832}\n",
      "\n",
      "===== Lowest test_mse =====\n",
      "Iteration   : 741\n",
      "Timestamp   : 2025-08-08 18:07:16.230345472\n",
      "train_mse   : 0.028682\n",
      "test_mse    : 0.013105\n",
      "train_r2    : 0.045608\n",
      "test_r2     : 0.009950\n",
      "params      :\n",
      "{'colsample_bytree': 0.500413,\n",
      " 'device': 'cuda',\n",
      " 'gamma': 1.077876,\n",
      " 'learning_rate': 0.208581,\n",
      " 'max_depth': 14,\n",
      " 'min_child_weight': 8,\n",
      " 'n_estimators': 2150,\n",
      " 'n_jobs': -1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': 220.784026,\n",
      " 'reg_lambda': 3650.307704,\n",
      " 'subsample': 0.876951}\n",
      "\n",
      "===== Highest train_r2 =====\n",
      "Iteration   : 249\n",
      "Timestamp   : 2025-08-08 17:45:44.365824\n",
      "train_mse   : 0.005010\n",
      "test_mse    : 0.018217\n",
      "train_r2    : 0.833303\n",
      "test_r2     : -0.376188\n",
      "params      :\n",
      "{'colsample_bytree': 0.360569,\n",
      " 'device': 'cuda',\n",
      " 'gamma': 0.003303,\n",
      " 'learning_rate': 0.184417,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8,\n",
      " 'n_estimators': 3250,\n",
      " 'n_jobs': -1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': 24.718484,\n",
      " 'reg_lambda': 4214.830235,\n",
      " 'subsample': 0.547832}\n",
      "\n",
      "===== Highest test_r2 =====\n",
      "Iteration   : 741\n",
      "Timestamp   : 2025-08-08 18:07:16.230345472\n",
      "train_mse   : 0.028682\n",
      "test_mse    : 0.013105\n",
      "train_r2    : 0.045608\n",
      "test_r2     : 0.009950\n",
      "params      :\n",
      "{'colsample_bytree': 0.500413,\n",
      " 'device': 'cuda',\n",
      " 'gamma': 1.077876,\n",
      " 'learning_rate': 0.208581,\n",
      " 'max_depth': 14,\n",
      " 'min_child_weight': 8,\n",
      " 'n_estimators': 2150,\n",
      " 'n_jobs': -1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': 220.784026,\n",
      " 'reg_lambda': 3650.307704,\n",
      " 'subsample': 0.876951}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from pprint import pformat\n",
    "\n",
    "csv_path = \"/Users/mazin/Desktop/hyperopt_live_log.csv\"\n",
    "\n",
    "def parse_params(s):\n",
    "    if isinstance(s, str) and s.strip().startswith(\"{\"):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return s\n",
    "    return s\n",
    "\n",
    "def round_floats(obj, ndigits=6):\n",
    "    if isinstance(obj, float):\n",
    "        return round(obj, ndigits)\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: round_floats(v, ndigits) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return type(obj)(round_floats(v, ndigits) for v in obj)\n",
    "    return obj\n",
    "\n",
    "def print_row(row, title):\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    print(f\"Iteration   : {int(row['iteration']) if pd.notna(row['iteration']) else row['iteration']}\")\n",
    "    if 'timestamp_dt' in row and pd.notna(row['timestamp_dt']):\n",
    "        print(f\"Timestamp   : {row['timestamp_dt']}\")\n",
    "    elif 'timestamp' in row and pd.notna(row['timestamp']):\n",
    "        print(f\"Timestamp   : {pd.to_datetime(row['timestamp'], unit='s', errors='coerce')}\")\n",
    "    print(f\"train_mse   : {row['train_mse']:.6f}\")\n",
    "    print(f\"test_mse    : {row['test_mse']:.6f}\")\n",
    "    print(f\"train_r2    : {row['train_r2']:.6f}\")\n",
    "    print(f\"test_r2     : {row['test_r2']:.6f}\")\n",
    "    params = row.get('params', None)\n",
    "    if params is not None:\n",
    "        params = round_floats(params, 6)\n",
    "        print(\"params      :\")\n",
    "        print(pformat(params, width=100, sort_dicts=True))\n",
    "\n",
    "# --- load & clean ---\n",
    "df = pd.read_csv(csv_path, converters={\"params\": parse_params})\n",
    "for c in [\"train_mse\", \"train_r2\", \"test_mse\", \"test_r2\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "if \"timestamp\" in df.columns:\n",
    "    df[\"timestamp_dt\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "# --- locate winners ---\n",
    "print_row(df.loc[df[\"train_mse\"].idxmin()], \"Lowest train_mse\")\n",
    "print_row(df.loc[df[\"test_mse\"].idxmin()],  \"Lowest test_mse\")\n",
    "print_row(df.loc[df[\"train_r2\"].idxmax()],  \"Highest train_r2\")\n",
    "print_row(df.loc[df[\"test_r2\"].idxmax()],   \"Highest test_r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc541be-3ae4-4a15-a8f3-ef6f889d4740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Top 20 LOWEST train_mse\n",
      "====================================================================================================\n",
      " rank  iteration  train_mse  test_mse  train_r2   test_r2           timestamp                                                                                                                                                                params_summary\n",
      "    1        249   0.005010  0.018217  0.833303 -0.376188 2025-08-08 17:45:44  learning_rate=0.18442, n_estimators=3250, max_depth=9, min_child_weight=8, gamma=0.0033028, subsample=0.54783, colsample_bytree=0.36057, reg_alpha=24.718, reg_lambda=4214.8\n",
      "    2        681   0.008481  0.016640  0.717809 -0.257106 2025-08-08 18:04:30  learning_rate=0.12912, n_estimators=1850, max_depth=6, min_child_weight=10, gamma=0.032793, subsample=0.91169, colsample_bytree=0.44973, reg_alpha=14.534, reg_lambda=1177.8\n",
      "    3        382   0.009588  0.015351  0.680952 -0.159725 2025-08-08 17:52:20    learning_rate=0.17935, n_estimators=3550, max_depth=11, min_child_weight=9, gamma=0.12222, subsample=0.9851, colsample_bytree=0.39052, reg_alpha=0.8845, reg_lambda=3955.1\n",
      "    4        956   0.009808  0.014630  0.673643 -0.105202 2025-08-08 18:18:04    learning_rate=0.13429, n_estimators=1600, max_depth=14, min_child_weight=8, gamma=0.2162, subsample=0.95374, colsample_bytree=0.48405, reg_alpha=0.057103, reg_lambda=2632\n",
      "    5        689   0.010122  0.015194  0.663190 -0.147827 2025-08-08 18:04:52   learning_rate=0.1386, n_estimators=3150, max_depth=9, min_child_weight=12, gamma=0.16575, subsample=0.8634, colsample_bytree=0.28205, reg_alpha=0.063803, reg_lambda=1405.6\n",
      "    6        748   0.010529  0.015028  0.649633 -0.135311 2025-08-08 18:07:33    learning_rate=0.21512, n_estimators=1500, max_depth=14, min_child_weight=9, gamma=0.21292, subsample=0.8837, colsample_bytree=0.56739, reg_alpha=5.2481, reg_lambda=2702.6\n",
      "    7        569   0.011080  0.014878  0.631326 -0.123972 2025-08-08 17:59:40 learning_rate=0.15073, n_estimators=150, max_depth=11, min_child_weight=12, gamma=0.0057577, subsample=0.91579, colsample_bytree=0.60245, reg_alpha=6.9004, reg_lambda=3665.9\n",
      "    8        482   0.011772  0.015226  0.608284 -0.150227 2025-08-08 17:55:06    learning_rate=0.11111, n_estimators=500, max_depth=8, min_child_weight=9, gamma=0.082605, subsample=0.97104, colsample_bytree=0.36851, reg_alpha=12.856, reg_lambda=3347.8\n",
      "    9        477   0.012305  0.014445  0.590538 -0.091283 2025-08-08 17:54:58  learning_rate=0.091102, n_estimators=650, max_depth=13, min_child_weight=10, gamma=0.25176, subsample=0.98327, colsample_bytree=0.43117, reg_alpha=11.111, reg_lambda=2353.1\n",
      "   10        369   0.012578  0.014670  0.581456 -0.108229 2025-08-08 17:51:42  learning_rate=0.20122, n_estimators=2350, max_depth=24, min_child_weight=12, gamma=0.30909, subsample=0.96155, colsample_bytree=0.42961, reg_alpha=1.5381, reg_lambda=5160.8\n",
      "   11        990   0.013490  0.014055  0.551131 -0.061769 2025-08-08 18:19:45     learning_rate=0.093107, n_estimators=1300, max_depth=12, min_child_weight=10, gamma=0.34006, subsample=0.923, colsample_bytree=0.45905, reg_alpha=3.57, reg_lambda=1886.1\n",
      "   12        838   0.013593  0.014929  0.547702 -0.127810 2025-08-08 18:12:03    learning_rate=0.15935, n_estimators=1800, max_depth=9, min_child_weight=11, gamma=0.18965, subsample=0.98371, colsample_bytree=0.5362, reg_alpha=14.024, reg_lambda=3745.7\n",
      "   13        759   0.014209  0.014144  0.527189 -0.068510 2025-08-08 18:08:04  learning_rate=0.21002, n_estimators=2050, max_depth=15, min_child_weight=11, gamma=0.64036, subsample=0.88027, colsample_bytree=0.45534, reg_alpha=0.9482, reg_lambda=813.14\n",
      "   14        335   0.014583  0.014760  0.514747 -0.115070 2025-08-08 17:50:04  learning_rate=0.27966, n_estimators=1550, max_depth=22, min_child_weight=11, gamma=0.31655, subsample=0.80845, colsample_bytree=0.50729, reg_alpha=14.618, reg_lambda=3725.6\n",
      "   15        491   0.014796  0.015017  0.507676 -0.134450 2025-08-08 17:55:28   learning_rate=0.16048, n_estimators=1400, max_depth=7, min_child_weight=13, gamma=0.19572, subsample=0.96973, colsample_bytree=0.37906, reg_alpha=12.778, reg_lambda=2912.1\n",
      "   16        297   0.015301  0.014347  0.490879 -0.083876 2025-08-08 17:48:00   learning_rate=0.18447, n_estimators=2200, max_depth=14, min_child_weight=8, gamma=0.60111, subsample=0.98365, colsample_bytree=0.82027, reg_alpha=2.1833, reg_lambda=2444.5\n",
      "   17        303   0.015399  0.014220  0.487595 -0.074223 2025-08-08 17:48:20  learning_rate=0.15007, n_estimators=2500, max_depth=21, min_child_weight=11, gamma=0.41339, subsample=0.92491, colsample_bytree=0.56575, reg_alpha=17.409, reg_lambda=3560.6\n",
      "   18        620   0.015954  0.014153  0.469134 -0.069179 2025-08-08 18:02:07     learning_rate=0.19201, n_estimators=2800, max_depth=9, min_child_weight=7, gamma=0.34224, subsample=0.98237, colsample_bytree=0.41397, reg_alpha=11.54, reg_lambda=3428.8\n",
      "   19        975   0.016272  0.014507  0.458547 -0.095967 2025-08-08 18:19:01     learning_rate=0.26613, n_estimators=2400, max_depth=14, min_child_weight=9, gamma=0.72701, subsample=0.91505, colsample_bytree=0.56976, reg_alpha=4.9716, reg_lambda=1497\n",
      "   20        188   0.016413  0.013909  0.453853 -0.050730 2025-08-08 17:42:06    learning_rate=0.11718, n_estimators=3000, max_depth=9, min_child_weight=9, gamma=0.46105, subsample=0.97796, colsample_bytree=0.39286, reg_alpha=1.2109, reg_lambda=2353.9\n",
      "\n",
      "====================================================================================================\n",
      "Top 20 LOWEST test_mse\n",
      "====================================================================================================\n",
      " rank  iteration  train_mse  test_mse  train_r2  test_r2           timestamp                                                                                                                                                               params_summary\n",
      "    1        741   0.028682  0.013105  0.045608 0.009950 2025-08-08 18:07:16   learning_rate=0.20858, n_estimators=2150, max_depth=14, min_child_weight=8, gamma=1.0779, subsample=0.87695, colsample_bytree=0.50041, reg_alpha=220.78, reg_lambda=3650.3\n",
      "    2        808   0.028512  0.013138  0.051271 0.007447 2025-08-08 18:10:27    learning_rate=0.14705, n_estimators=2550, max_depth=8, min_child_weight=10, gamma=1.2879, subsample=0.87314, colsample_bytree=0.49215, reg_alpha=175.1, reg_lambda=4315.9\n",
      "    3        194   0.029373  0.013141  0.022615 0.007232 2025-08-08 17:42:25   learning_rate=0.16056, n_estimators=3300, max_depth=8, min_child_weight=10, gamma=0.12023, subsample=0.97144, colsample_bytree=0.3793, reg_alpha=611.59, reg_lambda=3707.1\n",
      "    4        505   0.028409  0.013151  0.054695 0.006460 2025-08-08 17:55:59   learning_rate=0.14824, n_estimators=3750, max_depth=9, min_child_weight=9, gamma=0.72367, subsample=0.84702, colsample_bytree=0.40973, reg_alpha=220.35, reg_lambda=2276.8\n",
      "    5        631   0.027468  0.013154  0.086019 0.006300 2025-08-08 18:02:35    learning_rate=0.14985, n_estimators=1750, max_depth=9, min_child_weight=10, gamma=0.79151, subsample=0.83805, colsample_bytree=0.54101, reg_alpha=134.01, reg_lambda=3530\n",
      "    6        451   0.029255  0.013157  0.026551 0.006014 2025-08-08 17:54:18   learning_rate=0.18007, n_estimators=1450, max_depth=7, min_child_weight=8, gamma=0.46948, subsample=0.84801, colsample_bytree=0.47067, reg_alpha=409.48, reg_lambda=2681.1\n",
      "    7        186   0.027764  0.013158  0.076165 0.005956 2025-08-08 17:41:59 learning_rate=0.20938, n_estimators=2100, max_depth=13, min_child_weight=10, gamma=0.47314, subsample=0.99914, colsample_bytree=0.65974, reg_alpha=250.71, reg_lambda=3676.1\n",
      "    8        469   0.028490  0.013163  0.052006 0.005624 2025-08-08 17:54:47   learning_rate=0.11006, n_estimators=850, max_depth=10, min_child_weight=10, gamma=0.81057, subsample=0.89247, colsample_bytree=0.42213, reg_alpha=208.5, reg_lambda=2277.4\n",
      "    9        711   0.028115  0.013163  0.064464 0.005601 2025-08-08 18:05:45      learning_rate=0.13358, n_estimators=2450, max_depth=6, min_child_weight=7, gamma=1.066, subsample=0.9034, colsample_bytree=0.51782, reg_alpha=152.12, reg_lambda=3625.2\n",
      "   10        389   0.028865  0.013164  0.039515 0.005528 2025-08-08 17:52:39   learning_rate=0.12242, n_estimators=450, max_depth=5, min_child_weight=10, gamma=0.85449, subsample=0.82881, colsample_bytree=0.34495, reg_alpha=207.24, reg_lambda=6219.6\n",
      "   11        943   0.028401  0.013170  0.054960 0.005083 2025-08-08 18:17:28  learning_rate=0.073107, n_estimators=1950, max_depth=10, min_child_weight=13, gamma=1.058, subsample=0.84188, colsample_bytree=0.50607, reg_alpha=171.89, reg_lambda=3692.6\n",
      "   12        921   0.029271  0.013171  0.026014 0.005018 2025-08-08 18:16:16      learning_rate=0.19823, n_estimators=950, max_depth=6, min_child_weight=6, gamma=0.26412, subsample=0.87729, colsample_bytree=0.62402, reg_alpha=459.19, reg_lambda=2483\n",
      "   13        187   0.028129  0.013171  0.064001 0.004998 2025-08-08 17:42:02 learning_rate=0.15931, n_estimators=2100, max_depth=13, min_child_weight=10, gamma=0.48063, subsample=0.99977, colsample_bytree=0.39267, reg_alpha=250.99, reg_lambda=2742.2\n",
      "   14        580   0.029108  0.013171  0.031435 0.004992 2025-08-08 18:00:18  learning_rate=0.13787, n_estimators=2750, max_depth=15, min_child_weight=10, gamma=0.49847, subsample=0.9714, colsample_bytree=0.40708, reg_alpha=425.81, reg_lambda=2992.6\n",
      "   15        951   0.028416  0.013171  0.054456 0.004989 2025-08-08 18:17:51   learning_rate=0.12489, n_estimators=3350, max_depth=7, min_child_weight=13, gamma=0.7433, subsample=0.79613, colsample_bytree=0.39443, reg_alpha=182.79, reg_lambda=1865.1\n",
      "   16        790   0.028297  0.013173  0.058420 0.004832 2025-08-08 18:09:35    learning_rate=0.13032, n_estimators=2600, max_depth=9, min_child_weight=6, gamma=1.3255, subsample=0.87957, colsample_bytree=0.56056, reg_alpha=144.45, reg_lambda=4265.5\n",
      "   17        390   0.028730  0.013174  0.044007 0.004773 2025-08-08 17:52:41  learning_rate=0.073652, n_estimators=1150, max_depth=4, min_child_weight=7, gamma=0.69917, subsample=0.69791, colsample_bytree=0.23388, reg_alpha=139.11, reg_lambda=8037.9\n",
      "   18        692   0.028550  0.013177  0.050015 0.004532 2025-08-08 18:04:59   learning_rate=0.18379, n_estimators=2400, max_depth=7, min_child_weight=10, gamma=0.67864, subsample=0.9239, colsample_bytree=0.38224, reg_alpha=245.54, reg_lambda=1637.3\n",
      "   19        563   0.029424  0.013179  0.020930 0.004390 2025-08-08 17:59:27     learning_rate=0.15716, n_estimators=850, max_depth=7, min_child_weight=9, gamma=1.0941, subsample=0.83779, colsample_bytree=0.40632, reg_alpha=368.98, reg_lambda=3005.1\n",
      "   20       1007   0.029021  0.013180  0.034339 0.004304 2025-08-08 18:20:32  learning_rate=0.15203, n_estimators=1100, max_depth=14, min_child_weight=9, gamma=0.84744, subsample=0.92441, colsample_bytree=0.40659, reg_alpha=312.28, reg_lambda=3085.7\n",
      "\n",
      "====================================================================================================\n",
      "Top 20 HIGHEST train_r2\n",
      "====================================================================================================\n",
      " rank  iteration  train_mse  test_mse  train_r2   test_r2           timestamp                                                                                                                                                                params_summary\n",
      "    1        249   0.005010  0.018217  0.833303 -0.376188 2025-08-08 17:45:44  learning_rate=0.18442, n_estimators=3250, max_depth=9, min_child_weight=8, gamma=0.0033028, subsample=0.54783, colsample_bytree=0.36057, reg_alpha=24.718, reg_lambda=4214.8\n",
      "    2        681   0.008481  0.016640  0.717809 -0.257106 2025-08-08 18:04:30  learning_rate=0.12912, n_estimators=1850, max_depth=6, min_child_weight=10, gamma=0.032793, subsample=0.91169, colsample_bytree=0.44973, reg_alpha=14.534, reg_lambda=1177.8\n",
      "    3        382   0.009588  0.015351  0.680952 -0.159725 2025-08-08 17:52:20    learning_rate=0.17935, n_estimators=3550, max_depth=11, min_child_weight=9, gamma=0.12222, subsample=0.9851, colsample_bytree=0.39052, reg_alpha=0.8845, reg_lambda=3955.1\n",
      "    4        956   0.009808  0.014630  0.673643 -0.105202 2025-08-08 18:18:04    learning_rate=0.13429, n_estimators=1600, max_depth=14, min_child_weight=8, gamma=0.2162, subsample=0.95374, colsample_bytree=0.48405, reg_alpha=0.057103, reg_lambda=2632\n",
      "    5        689   0.010122  0.015194  0.663190 -0.147827 2025-08-08 18:04:52   learning_rate=0.1386, n_estimators=3150, max_depth=9, min_child_weight=12, gamma=0.16575, subsample=0.8634, colsample_bytree=0.28205, reg_alpha=0.063803, reg_lambda=1405.6\n",
      "    6        748   0.010529  0.015028  0.649633 -0.135311 2025-08-08 18:07:33    learning_rate=0.21512, n_estimators=1500, max_depth=14, min_child_weight=9, gamma=0.21292, subsample=0.8837, colsample_bytree=0.56739, reg_alpha=5.2481, reg_lambda=2702.6\n",
      "    7        569   0.011080  0.014878  0.631326 -0.123972 2025-08-08 17:59:40 learning_rate=0.15073, n_estimators=150, max_depth=11, min_child_weight=12, gamma=0.0057577, subsample=0.91579, colsample_bytree=0.60245, reg_alpha=6.9004, reg_lambda=3665.9\n",
      "    8        482   0.011772  0.015226  0.608284 -0.150227 2025-08-08 17:55:06    learning_rate=0.11111, n_estimators=500, max_depth=8, min_child_weight=9, gamma=0.082605, subsample=0.97104, colsample_bytree=0.36851, reg_alpha=12.856, reg_lambda=3347.8\n",
      "    9        477   0.012305  0.014445  0.590538 -0.091283 2025-08-08 17:54:58  learning_rate=0.091102, n_estimators=650, max_depth=13, min_child_weight=10, gamma=0.25176, subsample=0.98327, colsample_bytree=0.43117, reg_alpha=11.111, reg_lambda=2353.1\n",
      "   10        369   0.012578  0.014670  0.581456 -0.108229 2025-08-08 17:51:42  learning_rate=0.20122, n_estimators=2350, max_depth=24, min_child_weight=12, gamma=0.30909, subsample=0.96155, colsample_bytree=0.42961, reg_alpha=1.5381, reg_lambda=5160.8\n",
      "   11        990   0.013490  0.014055  0.551131 -0.061769 2025-08-08 18:19:45     learning_rate=0.093107, n_estimators=1300, max_depth=12, min_child_weight=10, gamma=0.34006, subsample=0.923, colsample_bytree=0.45905, reg_alpha=3.57, reg_lambda=1886.1\n",
      "   12        838   0.013593  0.014929  0.547702 -0.127810 2025-08-08 18:12:03    learning_rate=0.15935, n_estimators=1800, max_depth=9, min_child_weight=11, gamma=0.18965, subsample=0.98371, colsample_bytree=0.5362, reg_alpha=14.024, reg_lambda=3745.7\n",
      "   13        759   0.014209  0.014144  0.527189 -0.068510 2025-08-08 18:08:04  learning_rate=0.21002, n_estimators=2050, max_depth=15, min_child_weight=11, gamma=0.64036, subsample=0.88027, colsample_bytree=0.45534, reg_alpha=0.9482, reg_lambda=813.14\n",
      "   14        335   0.014583  0.014760  0.514747 -0.115070 2025-08-08 17:50:04  learning_rate=0.27966, n_estimators=1550, max_depth=22, min_child_weight=11, gamma=0.31655, subsample=0.80845, colsample_bytree=0.50729, reg_alpha=14.618, reg_lambda=3725.6\n",
      "   15        491   0.014796  0.015017  0.507676 -0.134450 2025-08-08 17:55:28   learning_rate=0.16048, n_estimators=1400, max_depth=7, min_child_weight=13, gamma=0.19572, subsample=0.96973, colsample_bytree=0.37906, reg_alpha=12.778, reg_lambda=2912.1\n",
      "   16        297   0.015301  0.014347  0.490879 -0.083876 2025-08-08 17:48:00   learning_rate=0.18447, n_estimators=2200, max_depth=14, min_child_weight=8, gamma=0.60111, subsample=0.98365, colsample_bytree=0.82027, reg_alpha=2.1833, reg_lambda=2444.5\n",
      "   17        303   0.015399  0.014220  0.487595 -0.074223 2025-08-08 17:48:20  learning_rate=0.15007, n_estimators=2500, max_depth=21, min_child_weight=11, gamma=0.41339, subsample=0.92491, colsample_bytree=0.56575, reg_alpha=17.409, reg_lambda=3560.6\n",
      "   18        620   0.015954  0.014153  0.469134 -0.069179 2025-08-08 18:02:07     learning_rate=0.19201, n_estimators=2800, max_depth=9, min_child_weight=7, gamma=0.34224, subsample=0.98237, colsample_bytree=0.41397, reg_alpha=11.54, reg_lambda=3428.8\n",
      "   19        975   0.016272  0.014507  0.458547 -0.095967 2025-08-08 18:19:01     learning_rate=0.26613, n_estimators=2400, max_depth=14, min_child_weight=9, gamma=0.72701, subsample=0.91505, colsample_bytree=0.56976, reg_alpha=4.9716, reg_lambda=1497\n",
      "   20        188   0.016413  0.013909  0.453853 -0.050730 2025-08-08 17:42:06    learning_rate=0.11718, n_estimators=3000, max_depth=9, min_child_weight=9, gamma=0.46105, subsample=0.97796, colsample_bytree=0.39286, reg_alpha=1.2109, reg_lambda=2353.9\n",
      "\n",
      "====================================================================================================\n",
      "Top 20 HIGHEST test_r2\n",
      "====================================================================================================\n",
      " rank  iteration  train_mse  test_mse  train_r2  test_r2           timestamp                                                                                                                                                               params_summary\n",
      "    1        741   0.028682  0.013105  0.045608 0.009950 2025-08-08 18:07:16   learning_rate=0.20858, n_estimators=2150, max_depth=14, min_child_weight=8, gamma=1.0779, subsample=0.87695, colsample_bytree=0.50041, reg_alpha=220.78, reg_lambda=3650.3\n",
      "    2        808   0.028512  0.013138  0.051271 0.007447 2025-08-08 18:10:27    learning_rate=0.14705, n_estimators=2550, max_depth=8, min_child_weight=10, gamma=1.2879, subsample=0.87314, colsample_bytree=0.49215, reg_alpha=175.1, reg_lambda=4315.9\n",
      "    3        194   0.029373  0.013141  0.022615 0.007232 2025-08-08 17:42:25   learning_rate=0.16056, n_estimators=3300, max_depth=8, min_child_weight=10, gamma=0.12023, subsample=0.97144, colsample_bytree=0.3793, reg_alpha=611.59, reg_lambda=3707.1\n",
      "    4        505   0.028409  0.013151  0.054695 0.006460 2025-08-08 17:55:59   learning_rate=0.14824, n_estimators=3750, max_depth=9, min_child_weight=9, gamma=0.72367, subsample=0.84702, colsample_bytree=0.40973, reg_alpha=220.35, reg_lambda=2276.8\n",
      "    5        631   0.027468  0.013154  0.086019 0.006300 2025-08-08 18:02:35    learning_rate=0.14985, n_estimators=1750, max_depth=9, min_child_weight=10, gamma=0.79151, subsample=0.83805, colsample_bytree=0.54101, reg_alpha=134.01, reg_lambda=3530\n",
      "    6        451   0.029255  0.013157  0.026551 0.006014 2025-08-08 17:54:18   learning_rate=0.18007, n_estimators=1450, max_depth=7, min_child_weight=8, gamma=0.46948, subsample=0.84801, colsample_bytree=0.47067, reg_alpha=409.48, reg_lambda=2681.1\n",
      "    7        186   0.027764  0.013158  0.076165 0.005956 2025-08-08 17:41:59 learning_rate=0.20938, n_estimators=2100, max_depth=13, min_child_weight=10, gamma=0.47314, subsample=0.99914, colsample_bytree=0.65974, reg_alpha=250.71, reg_lambda=3676.1\n",
      "    8        469   0.028490  0.013163  0.052006 0.005624 2025-08-08 17:54:47   learning_rate=0.11006, n_estimators=850, max_depth=10, min_child_weight=10, gamma=0.81057, subsample=0.89247, colsample_bytree=0.42213, reg_alpha=208.5, reg_lambda=2277.4\n",
      "    9        711   0.028115  0.013163  0.064464 0.005601 2025-08-08 18:05:45      learning_rate=0.13358, n_estimators=2450, max_depth=6, min_child_weight=7, gamma=1.066, subsample=0.9034, colsample_bytree=0.51782, reg_alpha=152.12, reg_lambda=3625.2\n",
      "   10        389   0.028865  0.013164  0.039515 0.005528 2025-08-08 17:52:39   learning_rate=0.12242, n_estimators=450, max_depth=5, min_child_weight=10, gamma=0.85449, subsample=0.82881, colsample_bytree=0.34495, reg_alpha=207.24, reg_lambda=6219.6\n",
      "   11        943   0.028401  0.013170  0.054960 0.005083 2025-08-08 18:17:28  learning_rate=0.073107, n_estimators=1950, max_depth=10, min_child_weight=13, gamma=1.058, subsample=0.84188, colsample_bytree=0.50607, reg_alpha=171.89, reg_lambda=3692.6\n",
      "   12        921   0.029271  0.013171  0.026014 0.005018 2025-08-08 18:16:16      learning_rate=0.19823, n_estimators=950, max_depth=6, min_child_weight=6, gamma=0.26412, subsample=0.87729, colsample_bytree=0.62402, reg_alpha=459.19, reg_lambda=2483\n",
      "   13        187   0.028129  0.013171  0.064001 0.004998 2025-08-08 17:42:02 learning_rate=0.15931, n_estimators=2100, max_depth=13, min_child_weight=10, gamma=0.48063, subsample=0.99977, colsample_bytree=0.39267, reg_alpha=250.99, reg_lambda=2742.2\n",
      "   14        580   0.029108  0.013171  0.031435 0.004992 2025-08-08 18:00:18  learning_rate=0.13787, n_estimators=2750, max_depth=15, min_child_weight=10, gamma=0.49847, subsample=0.9714, colsample_bytree=0.40708, reg_alpha=425.81, reg_lambda=2992.6\n",
      "   15        951   0.028416  0.013171  0.054456 0.004989 2025-08-08 18:17:51   learning_rate=0.12489, n_estimators=3350, max_depth=7, min_child_weight=13, gamma=0.7433, subsample=0.79613, colsample_bytree=0.39443, reg_alpha=182.79, reg_lambda=1865.1\n",
      "   16        790   0.028297  0.013173  0.058420 0.004832 2025-08-08 18:09:35    learning_rate=0.13032, n_estimators=2600, max_depth=9, min_child_weight=6, gamma=1.3255, subsample=0.87957, colsample_bytree=0.56056, reg_alpha=144.45, reg_lambda=4265.5\n",
      "   17        390   0.028730  0.013174  0.044007 0.004773 2025-08-08 17:52:41  learning_rate=0.073652, n_estimators=1150, max_depth=4, min_child_weight=7, gamma=0.69917, subsample=0.69791, colsample_bytree=0.23388, reg_alpha=139.11, reg_lambda=8037.9\n",
      "   18        692   0.028550  0.013177  0.050015 0.004532 2025-08-08 18:04:59   learning_rate=0.18379, n_estimators=2400, max_depth=7, min_child_weight=10, gamma=0.67864, subsample=0.9239, colsample_bytree=0.38224, reg_alpha=245.54, reg_lambda=1637.3\n",
      "   19        563   0.029424  0.013179  0.020930 0.004390 2025-08-08 17:59:27     learning_rate=0.15716, n_estimators=850, max_depth=7, min_child_weight=9, gamma=1.0941, subsample=0.83779, colsample_bytree=0.40632, reg_alpha=368.98, reg_lambda=3005.1\n",
      "   20       1007   0.029021  0.013180  0.034339 0.004304 2025-08-08 18:20:32  learning_rate=0.15203, n_estimators=1100, max_depth=14, min_child_weight=9, gamma=0.84744, subsample=0.92441, colsample_bytree=0.40659, reg_alpha=312.28, reg_lambda=3085.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# --- path ---\n",
    "csv_path = \"/Users/mazin/Desktop/hyperopt_live_log.csv\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def parse_params(s):\n",
    "    if isinstance(s, str) and s.strip().startswith(\"{\"):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return s\n",
    "    return s\n",
    "\n",
    "def summarize_params(p, ndigits=5):\n",
    "    \"\"\"Make a short one-line summary of the most useful hyperparams.\"\"\"\n",
    "    if not isinstance(p, dict):\n",
    "        return str(p)\n",
    "    keys = [\n",
    "        \"learning_rate\", \"n_estimators\", \"max_depth\", \"min_child_weight\",\n",
    "        \"gamma\", \"subsample\", \"colsample_bytree\", \"reg_alpha\", \"reg_lambda\"\n",
    "    ]\n",
    "    parts = []\n",
    "    for k in keys:\n",
    "        if k in p:\n",
    "            v = p[k]\n",
    "            if isinstance(v, float):\n",
    "                parts.append(f\"{k}={v:.{ndigits}g}\")\n",
    "            else:\n",
    "                parts.append(f\"{k}={v}\")\n",
    "    return \", \".join(parts)\n",
    "\n",
    "def make_table(df, sort_by, ascending, title, topn=20):\n",
    "    metrics = [\"train_mse\", \"test_mse\", \"train_r2\", \"test_r2\"]\n",
    "    top = (\n",
    "        df.sort_values(sort_by, ascending=ascending, na_position=\"last\")\n",
    "          .head(topn)\n",
    "          .copy()\n",
    "    )\n",
    "    top.insert(0, \"rank\", range(1, len(top) + 1))\n",
    "    # Round metrics for readability\n",
    "    for c in metrics:\n",
    "        top[c] = pd.to_numeric(top[c], errors=\"coerce\").round(6)\n",
    "    # Human timestamp + compact params\n",
    "    if \"timestamp_dt\" in top.columns:\n",
    "        top[\"timestamp\"] = top[\"timestamp_dt\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    elif \"timestamp\" in top.columns:\n",
    "        top[\"timestamp\"] = pd.to_datetime(top[\"timestamp\"], unit=\"s\", errors=\"coerce\").dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        top[\"timestamp\"] = \"\"\n",
    "    top[\"params_summary\"] = top[\"params\"].apply(summarize_params)\n",
    "\n",
    "    cols = [\"rank\", \"iteration\"] + metrics + [\"timestamp\", \"params_summary\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(title)\n",
    "    print(\"=\" * 100)\n",
    "    print(top[cols].to_string(index=False))\n",
    "    return top[cols]\n",
    "\n",
    "# ---------- load & clean ----------\n",
    "df = pd.read_csv(csv_path, converters={\"params\": parse_params})\n",
    "for c in [\"train_mse\", \"test_mse\", \"train_r2\", \"test_r2\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "if \"timestamp\" in df.columns:\n",
    "    df[\"timestamp_dt\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "# ---------- outputs ----------\n",
    "tbl_train_mse = make_table(df, \"train_mse\", True,  \"Top 20 LOWEST train_mse\")\n",
    "tbl_test_mse  = make_table(df, \"test_mse\",  True,  \"Top 20 LOWEST test_mse\")\n",
    "tbl_train_r2  = make_table(df, \"train_r2\",  False, \"Top 20 HIGHEST train_r2\")\n",
    "tbl_test_r2   = make_table(df, \"test_r2\",   False, \"Top 20 HIGHEST test_r2\")\n",
    "\n",
    "# (Optional) Save the readable tables to CSVs:\n",
    "# tbl_train_mse.to_csv(\"/Users/mazin/Desktop/top20_train_mse.csv\", index=False)\n",
    "# tbl_test_mse.to_csv(\"/Users/mazin/Desktop/top20_test_mse.csv\", index=False)\n",
    "# tbl_train_r2.to_csv(\"/Users/mazin/Desktop/top20_train_r2.csv\", index=False)\n",
    "# tbl_test_r2.to_csv(\"/Users/mazin/Desktop/top20_test_r2.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
